## Motivation

На протяжении истории развития вычислительных систем мы постоянно сталкиваемся с одной из главных проблем: "как эффективно утилизировать ресурс процессора, когда множество "задач" конкурируют за его внимание?". Первоначальным решением были процессы - изолированные друг от друга сущности со своим собственным адресным пространством, управляемые планировщиком операционной системы. Однако создание процесса и переключение контекста между ними - это дорогостоящие операции, влекущие за собой значительные накладные расходы.

Эволюционным шагом стало появление [потоков](obsidian://open?vault=my_notes&file=cs%2FConcurrency%2FThreads) (`threads`). Потоки существуют в рамках одного процесса и разделяют его виртуальное адресное пространство. Это значительно удешевило  создание и переключение контекста, поскольку ядру операционной системы не требовалось переключать таблицы страниц виртуальной памяти. Модель, используемая потоками, называется **вытесняющей многозадачностью (`preemptive multitasking`)**. В этой модели планировщик в любой момент времени может прервать выполнение одного потока и передать управление другому, основываясь на приоритетах или системных событиях.

Эта модель прекрасно работает для `CPU-bound` задач и для обеспечения отзывчивости пользовательских интерфейсов. Однако она демонстрирует свои слабые стороны в сценариях с экстремально высоким уровнем конкуренции, особенно для задач, ограниченных "вводом-выводом" (`I/O-bound`). В качестве такой задачи достаточно представить себе веб-сервер, который должен одновременно обслуживать десятки тысяч или даже сотни тысяч соединений. Каждое соединение большую часть времени ничего не делает - оно ждёт данных из сети. В таком случае при создании отдельного потока для каждого соединения может привести к катастрофе, так как каждый поток требует выделение стека в ядре и в пользовательском пространстве. 100000 потоков потребуют гигабайты памяти только под стеки. Также, даже относительно лёгкое переключение контекста потока требует использование системного вызова для перехода в режим ядра и обратно. Это сотни, а то и тысячи тактов процессора. Когда переключений очень много, суммарные накладные расходы становятся доминирующим фактором, снижающим производительность системы.

Однако, для (`I/O-bound`) задач крайне эффективно использование альтернативной парадигмы планирования - **кооперативной многозадачности (`Cooperative multitasking`)**. Данная парадигма реализуется через ***файберы***.

## Definition

***Файбер (`fiber`)*** - это легковесный поток исполнения, жизненный цикл которого полностью управляется в пользовательском адресном пространстве, без прямого участия планировщика операционной системы.

В различных контекстах можно встретить эквивалентные или близкие по значению термины: `green threads`, `user-space threads`, `tasklets` или `microthreads`. Часто используется термин "корутина" (`coroutine`), однако обычно он подразумевает реализацию на уровне языка программирования, в то время как файбер чаще относится к системной концепции. Для наших целей мы будем считать эти термины взаимозаменяемыми.

Ключевое отличие файбера от классического потока кроется в модели планирования. Вместо вытесняющей многозадачности, файберы реализуют кооперативную. **Это означает, что файбер будет выполняться до тех пор, пока он добровольно не передаст управление планировщику файберов.** Передача управления осуществляется явным вызовом специальной функции, например, yield(). Таким образом, идея переключения контекста переносится из пространства ядра в пространство пользователя, а сами переключения становятся осознанной и явной частью вычислительного процесса.

## Internals

Прежде чем погружаться в детали реализации, необходимо провести фундаментальное различие между двумя моделями использования файберов.

- **Модель `N:1`** предполагает, что `N` файберов исполняются на одном-единственном потоке операционной системы. Весь асинхронный код выполняется последовательно на этом потоке, а файберы кооперативно делят его между собой. Эта модель лежит в основе `async/await` в `JavaScript` и `Python`, а также корутин в `Lua`. Ее главным преимуществом является отсутствие проблем с гонкой данных, так как истинный параллелизм отсутствует. Однако она не позволяет полноценно раскрыть мощь многоядерных процессоров.

- **Модель `M:N`**  - это более сложная и мощная концепция, где `M` файберов распределяются для исполнения по пулу из `N` потоков  (`M > N`). Именно эта модель представляет наибольший интерес для высокопроизводительных приложений, так как она сочетает масштабируемость файберов с истинным параллелизмом потоков. **Важно понимать: в модели `M:N` все классические проблемы многопоточности, такие как гонки данных, взаимоблокировки (`deadlocks`) и необходимость синхронизации, возвращаются**, поскольку несколько файберов могут исполняться действительно параллельно на разных ядрах процессора.


Далее мы будем рассматривать механизм работы файберов преимущественно в контексте более общей и сложной модели `M:N`.

- **Контекст исполнения** - это `snapshot` состояния процессора, необходимый для продолжения вычислений с прерванного места. Контекст обычно включает в себя:
	- `Instruction pointer (rip/eip)` - адрес следующей инструкции для выполнения.
	- `Stack pointer (rsp/esp)` - вершина стека файбера.
	- Значения регистров общего назначения (`rax, rbx, ...`) - значения операндов, используемых в текущих вычислениях

- `Stack` - у каждого файбера есть собственный, отдельный стек. Он используется для хранения локальных переменных, адресов возврата, точно также, как и у классического потока. Размер этого стека значительно меньше, чем у классического потока. Наличие собственного стека — это то, что определяет файберы как `stackful coroutines`. Это позволяет писать код в привычном процедурном стиле, с вызовами функций, локальными переменными и рекурсией, в отличие от `stackless coroutines`, где компилятор должен преобразовывать код, накладывая ограничения на точки приостановки выполнения.

- Планировщик (`sheduler`) - это компонент, ответственный за управление файберами. В его ответственность входит создание и уничтожение файберов, хранение очереди готовых к исполнению файберов, сохранение контекста при вызове `yield`, восстановление контекста и передача управление следующему файберу из очереди. (+ В модели `M:N`, распределение файберов по рабочим потокам).

### Context switch

В отличие от потоков ОС, где переключение контекста — прерогатива ядра, файберы реализуют этот механизм в пространстве пользователя. Это достигается за счет прямого манипулирования регистрами процессора с помощью коротких ассемблерных вставок.

**Следует избегать системных примитивов для работы с контекстом**, таких как `ucontext` в `POSIX` или `CreateFiber` в `Windows`. Они либо устарели, либо несут избыточные накладные расходы, либо накладывают ограничения (например, не позволяют использовать собственный аллокатор для стеков).

Эффективная реализация сводится к двум  инструкциям, инкапсулирующим ассемблерные вставки, специфичным для конкретной архитектуры и `ABI`:

- `get_context(context*)`: Сохраняет значения критически важных регистров и `rip` в переданную структуру `context`

- `set_context(context*)`: Восстанавливает значения регистров из структуры `context` и выполняет нелокальный переход, фактически загружая в `rip` сохранённый адрес.

Комбинируя их, можно реализовать `swap_context(old_ctx*, new_ctx*)` — функцию, которая сохраняет текущий контекст в `old_ctx` и немедленно восстанавливает новый из `new_ctx`. Это сердце файбера.  

---

### `Coroutines : The Core of Fiber Design (M:N Model)`

Для построения масштабируемой системы многопоточных файберов, функционирующей по модели `M:N`, применяется фундаментальный паттерн декомпозиции. Его основной смысл заключается в создании архитектуры, в которой ключевые компоненты являются независимыми по отношению друг к другу, взаимодействуя посредством строго определённых интерфейсов. Таким подход добавляет модульность дизайну, а следует принципу разделения ответственности.

В случае многопоточных файберов, основная декомпозиция, предложенная в рамках данного подхода основывается на композиции отдельных компонент, относящихся, вообще говоря, к разным идиомам разработки, а именно : Планировщик (`ThreadPool`) и корутина (__как функциональный паттерн!!__).

1. `ThreadPool` выполняет роль низкоуровневого исполнителя неблокирующихся единиц работы. Он является основным исполнительным компонентом планировщика файберов и его основной обязанностью является принятие и выполнение произвольных задач (представленных `callable-objects`) на своих worker-потоках. Для `ThreadPool` полностью отсутствует понятие файбера или корутины; он воспринимает все поступающие задачи как абстрактные процедуры, которые требуется последовательно извлечь из очереди и вызвать.

2. Корутина является основным паттерном/моделью выполнения для организации кооперативной передачи управления (`caller-callee`) между различными точками исполнения в пределах одного потока операционной системы. Основная функция корутины заключается в инкапсуляции собственного контекста исполнения, включающего стек вызовов и состояние регистров процессора, что позволяет ей добровольно приостанавливать своё выполнение (`yield()`) и возобновлять его (`resume()`) из произвольной точки. В контексте дизайна файберов, тут принципиально, что корутина остаётся полностью независимой от высокоуровневых абстракций: она не имеет никакого представления или осведомлённости, ни о потоках, ни о планировщиках, ни об очереди задач. Её функциональность строго ограничена низкоуровневым управлением собственным контекстом исполнения.

3. `Fibers API` : Высокоуровневое `API` файберов как раз-таки служит связующим звеном / ребром между двумя этими независимыми вершинами. Фактически файбер является контейнером, инкапсулирующим в себе планировщик в виде `ThreadPool` и механизм кооперативной многозадачности в виде реализации паттерна корутины (контекста и его переключения). То есть его `API` транслирует намерение пользователя создать и запустить легковесную задачу (например через `fiber::Go(scheduler, task)`) в набор низкоуровневых операций, которые могут быть обработаны `ThreadPool`'ом и реализованы внутренне через паттерн корутин. В его ответственность входит управление жизненным циклом корутины, оборачивание её в исполняемую задачу (task), перепланирование, обработка точек приостановки и возобновления и контроля ресурсов при при завершении исполнения.

рассмотрим концептуальный пример, демонстрирующий взаимодействие компонент при запуске и управлении файбером, на примере все той же функции `fiber::Go`.


```C++
thread::WaitGroup wg;

for (size_t i = 0; i < 128; ++i) {
	wg.Add();
	
	fiber::Go(scheduler, [&]{
		Defer defer([&]{
			wg.Done;
		});
		
		for (size_t j = 0; j < 7; ++j) {
			fiber::Yield();
		}
	});
}


void ThreadPool::Work() {
	while (True) {
		Task next = tasks_.Pop();
		next();
	}
}
```


1. При вызове функции `fiber::Go`, которая например принимает ссылку на планировщик и пользовательский `callable-object` (например lambda)  в качестве тела файбера, система выполняет следующие логические шаги:

	* создаётся новый объект корутины. Этот объект будет содержать собственный стек исполнения и необходимый контекст для исполнения переданной лямбды.

	* Создаётся служебный объект `Task` (`callable`). Данный объект инкапсулирует логику управления только что созданной корутиной. Его основная обязанность = инициировать или возобновлять исполнение корутины посредством вызова `coroutine.resume()`.

	* Сформированная `Task` передаётся в очередь планировщика (`ThreadPool`), который в свою очередь, ожидает появления задач для выполнения

2. `ThreadPool -> Task -> coro.resume()`
	- Один из свободных рабочих потоков извлекает ранее переданную `Task` и начинает ее исполнение.

	- Внутри объекта `Task` происходит первый вызов `coro.resume()`. Этот вызов передаёт управление в пользовательскую лямбду, инициируя её исполнение.

3. `fiber::Yield()`
	- Во время исполнения, лямбда достигает вызова `fiber::Yield()`.

	- На этом этапе корутина приостанавливает свое текущее выполнение. Весь необходимый для будущего возобновления контекст сохраняется в объекте корутины.

	- Управление возвращается из метода `resume()` обратно в `Task - caller`, которая вызвала его ранее.

	- Объект задачи, определяя, что корутина была приостановлена, но не завершена, инициирует процесс перепланировки. Она создаёт или обновляет другой `Task`-объект, который будет представлять продолжение выполнения этой же корутины, и помещает эту задачу в конец очереди планировщика.

	- Текущая задача завершает свою работу, освобождая рабочий поток для обработки других задач.

4. `Resuming again`
	- В какой-то момент, после того, как рабочий поток обработает другие доступные задачи, из очереди `ThreadPool` будет извлечена та самая `resuming Task`.

	- Данная задача повторно вызовет `coro.resume()`. Исполнение файбера возобновляется ровно с того момента, где оно было приостановлено ранее. Цикл продолжения-приостановки повторяется до полного выполнения логики файбера.

5. `Finishing`

	- После того, как пользовательская лямбда полностью завершает свою работу, корутина завершает своё исполнение. `coro.resume()` в последний раз возвращает управление.


---
## Nested induced Deadlocks

Может возникнуть вопрос: чем модель `M:N` файберов отличается от классического пула потоков (`thread pool`), исполняющего задачи (`tasks`)? Различие фундаментально проявляется в проблеме, которую можно назвать **вложенно-индуцированной взаимоблокировкой**.

Представим загрузку игрового уровня: `LoadLevel` порождает задачи для загрузки моделей `LoadModel`, которые в свою очередь, порождают задачи `LoadMesh` и `LoadMaterial`, и так далее... Если на каждом уровне вложенности родительская задача будет ждать завершения дочерних, очень быстро все `N` потоков пула окажутся заблокированными в ожидании, в то время как порождённые ими задачи не смогут начать выполняться, так как свободных потоков в пуле не осталось. Это является наглядным представлением взаимоблокировки (`deadlock`).

Файберы красиво решают эту проблему. Когда файбер вызывает ожидающую функцию, она на самом деле не блокирует родительский для файбера поток, а вместо этого уступает управление (`yields`). Планировщик переводит текущий файбер в состояние ожидания и немедленно запускает на освободившемся потоке одну из дочерних задач. Таким образом, родительский поток всегда останется загруженным полезной работой.

---

На первый взгляд, модель кооперативной многозадачности выглядит безупречно, но у неё есть фундаментальная уязвимость. Что произойдёт, если один из файберов выполнит классический блокирующий системный вызов, например `read()` на сетевом сокете, в котором пока нет данных? В этот момент управление переходит к ядру операционной системы. Ядро, обнаружив, что операция не может быть выполнена немедленно, переводит весь родительский для файберов поток в состояние ожидания. Вместе с ним блокируется работа всех файберов, которые исполнялись в этом потоке. Вся элегантная система кооперативной многозадачности коллапсирует и производительность падает до нуля.

Избежать данную проблему возможно, если всегда следовать универсальному правилу работы с файберами. Оно гласит, что ***правильная реализация системы на файберах никогда не использует блокирующие системные вызовы напрямую.***


Как было сказано, модель файберов рушится, если один из них выполняет **блокирующий** системный вызов. Он замораживает весь родительский поток выполнения. 

Решение этой проблемы заключается в полной и безаговорочной замене всех блокирующих операций их асинхронными аналогами, построенными вокруг архитектурного паттерна `Reactor`. Вопреки распостранённому упрощению, роль реактора, как правило, не выделяется в отдельный специализированный поток. Вместо этого его функциональность интегрируется в основной рабочий цикл каждого потока пула, который исполняет файберы. Для пользователя это будет выглядеть как простой вызов `socket.read()`, который не блокирует систему. Внутри вызова же разворачивается сложная, но строгая упорядоченная последовательность действий.

В момент, когда `fiber` инициирует операцию ввода-вывода через предоставляемую библиотекой функцию-обёртку, первым делом совершается оптимистическая попытка выполнения в неблокирующем режиме. Если ресурс уже доступен в буфере ядра, он немедленно считывается, и функция возвращает результат, минуя все дальнейшие сложности. Если же данные отсутствуют, то вступает в работу основной механизм. Функция-обёртка регистрирует файловый дескриптор сокета через неблокирующее семейство системных вызовов (`epoll/kqueue/IOCP`), связывая его с контекстом текущего файбера. Эта связка - залог того, что система будет знать, кого именно поднимать в будущем. Сразу после успешной регистрации файбер добровольно уступает управление, вызывая `yeild()`, и переводится планировщиком файбера в состояние ожидания, не блокируя при этом родительский поток.

В этот момент поток пула продолжает свою работу: он исполняет другие готовые файберы, а в перерывах кратковременно опрашивает системный монитор событий вызовом `epoll_wait()` (или его аналогом в зависимости от системы). Этот вызов мгновенно возвращает список дескрипторов, на которых произошли события. Обрабатывая этот список, планировщик файберов использует сохранённую ранее связку, чтобы определить, какой файбер ожидал каждого конкретного события, и перемещает его из очереди ожидания обратно в очередь готовых к исполнению.

При следующей итерации планировщик файберов в конечном итоге выберет поднятый файбер и восстановит его контекст. Исполнение возобновится ровно с того места, где оно было приостановлено, - внутри функции-обёртки. Теперь она может повторить неблокирующий системный вызов, который на этот раз гарантированно завершится успехом. Для вызывающего кода вся эта сложная последовательность вызовов выглядит как единый, но не блокирующий систему вызов функции, что позволяет сохранить простоту синхронной модели программирования при сохранении эффективности асинхронности внутри.


---

## LINKS:

1. `boost/fiber`:
	- [class](https://www.boost.org/doc/libs/develop/libs/context/doc/html/context/ff.html)
	- [`context switching`](https://www.boost.org/doc/libs/develop/libs/context/doc/html/context/ff.html)
2. [`fibers without scheduler`](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0876r0.pdf)
3. [`overview`](https://graphitemaster.github.io/fibers/)
