# The Memory Hierarchy and Basic Concepts of Caching

***Кэш (cache)*** - это высокоскоростная память небольшого объёма, используемая для временного хранения данных или инструкций, к которым процессор обращается наиболее часто. Основным его преимуществом является снижение среднего времени доступа к данным.

В архитектуре `x86-64` кэш обычно организован в виде иерархии уровней (`L1, L2, L3`), где каждый из уровней имеет разную скорость и объём.

***Кэширование*** - это механизм управления кэшем, включающий поиск данных в кэше, их загрузку в кэш при промахе (`cache miss`) и вытеснение данных из кэша в соответствии с выбранной стратегией.


Как было указано ранее, кэш состоит из нескольких уровней. Каждый уровень кэша оптимизирован для баланса между скоростью доступа, объёмом и энергопотреблением.

Каждый из уровней представляет из себя набор транзисторов, организованных в триггеры (`flip-flops`), которые хранят биты данных.

Для начала рассмотрим общую идею кэширования в иерархии памяти.

![The memory hierarchy|550px](https://i.imgur.com/rI77oDl.png)


Иерархия памяти состоит из нескольких уровней, где каждый уровень (например, уровень `k` и уровень `k+1`) имеет свои характеристики по объему, скорости доступа и стоимости.

Память на каждом уровне иерархии разделена на **блоки** — непрерывные фрагменты данных. Блоки могут быть фиксированного или переменного размера.

Кэш на уровне `k` содержит копии подмножества блоков из уровня `k+1`. Например:

![levels](https://i.imgur.com/YzV3QhK.jpeg)


Это означает, что кэш хранит только часть данных из более медленной памяти, чтобы ускорить доступ к ним.

Данные передаются между уровнями `k` и `k+1` блоками фиксированного размера.

Устройства, находящиеся ниже в иерархии, имеют большее время доступа. Чтобы компенсировать это, используются блоки большего размера. Передача больших блоков данных позволяет "амортизировать" (распределить) длительное время доступа, так как за один запрос передается больше данных.

---
## Cache Hits

В момент, когда программе необходимо обратиться к определённому фрагменту данных `d`, хранящемуся на уровне `k+1`, происходит примерно следующее:

- Поиск в кэше уровня `k`, так как доступ к данным на этом уровне намного быстрее, чем к данным на следующем уровне
	
	- Попадание (`cache hit`)
		- Если блок данных `d` обнаруживается в кэше уровня `k`, это называется **попаданием в кэш**

	- Промах (`cache miss`)
		- Если блок данных `d` не найден на в кэше уровня `k`, это называется **промахом в кэш**
			- В этом случае процессор вынужден производить поиск в следующих уровнях, до того момента, пока не случится попадание.

---
## Cache misses

Теперь более подробно разберёмся с промахами.

Промах в кэш возникает при отсутствии искомого блока данных в текущем уровне кеша. В этом случае необходимо обратится к последующим уровням для поиска искомого блока/блоков. 

Этот процесс занимает больше времени, так как следующие уровни медленнее и иногда на много порядков.

После того, как блок с данными извлечён из уровня `k+1`, он копируется в кэш уровня `k`, чтобы ускорить доступ к этим данным в будущем

### Block replacement

Если же кэш уровня `k` уже заполнен, то для размещения нового блока необходимо **вытеснить** один из существующих блоков. Этот процесс называется **вытеснением блока**, а сам вытесненный блок называется **блоком-жертвой**.

Почему требуется вытеснение? Это следует из того, что каждый уровень кэша имеет имеет ограниченный объём.

Само вытеснение выполняется по одной из многих **стратегий замены (`Replacement Policies`)**. **Стратегия замены** определяет блок, который будет вытеснен из данного уровня кэша.

Существует множество распостранённых стратегий замены:

- `Random replacement`
	- Блок для вытеснения выбирается случайным образом (неэффективно)
- `Least Recently Used (LRU)`
	- Вытесняется блок, к которому не было обращений дольше всего. Если блок не использовался долгое время, он, скорее всего, не понадобится в ближайшем будущем.
- `First-In, First-Out (FIFO)`
	- Вытесняется блок, который находится в кеше дольше всего. Недостаток этой стратегии в том, что может вытесниться блок, который активно используется.
- `Least Frequently Used (LFU)`
	- Вытесняется блок, который использовался реже всего


### Kinds of cache misses

Однако промахи также делятся на категории. В этом пункте рассмотрим различные виды промахов кэша и их влияние на производительность системы.

#### Cold misses

"Холодные" промахи возникают в случае, когда кэш на уровне `k` пуст, и при первом обращении к любому блоку данных происходит промах. Такие промахи являются неизбежными, так как они происходят из-за отсутствия каких-либо блоков в кэше текущего уровня, а не из-за ограничений стратегий размещения или недостатка ёмкости.

Холодные промахи часто возникают в начале работы программы или при переходе к новому этапу выполнения.

#### Placement Policies

Помимо стратегий замены также существуют **стратегии размещения**. Они необходимы в ситуациях, когда происходит промах и система должна определить, куда разместить блок, полученный с уровня `k+1`.

Наиболее гибкой является стратегия, которая позволяет размещать блок с уровня `k+1` в любом блоке на уровне `k`. Однако для высоких уровней кэша в иерархии памяти данная стратегия не применима, ведь там быстродействие является основным приоритетом, а реализация произвольного размещения блоков в аппаратных кэшах требует больших затрат.

### Cache management

Программы часто выполняются как последовательность этапов и циклов, когда каждый этап получает доступ к более или менее постоянному множеству блоков в кэше. Например, вложенный цикл может многократно обращаться к элементам одного и того же массива. Это множество блоков называется **рабочим множеством** этапа или цикла программы.

---
# General organization of cache

Иерархии памяти первых компьютерных систем состояли всего из трёх уровней: регистров процессора, основной памяти `DRAM` и дисковых устройств.

Однако из-за увеличивающейся разницы в быстродействии между регистрами процессора и основной `DRAM` памятью проектировщики были вынуждены добавить `SRAM (Static Random Accessed Memory)` - кэш `L1`. Он расположен между блоком регистров и основной `DRAM` памятью и его время доступа сопоставимо со временем доступа к регистрам.

![|550px](https://i.imgur.com/4AOvyUj.png)

С увеличением разницы в быстродействии между процессорами и основной `DRAM` памятью проектировщики компьютерных систем были вынуждены вводить дополнительные уровни кешей. 

Это позволило еще больше сократить время ожидания процессора и повысить общую производительность систем. Таким образом были добавлены кэши `L2` и `L3`.

Общие принципы остались неизменны, за исключением того, что уровни `L2` и `L3` также встроились в иерархию памяти и упорядочены по времени доступа и объёму с каждым уровнем.

Далее мы рассмотрим общую структуру и внутреннее устройство почти любого кэша в современной вычислительной машине.

---

Рассмотрим компьютерную систему, в которой каждый адрес памяти состоит из `m` байт. Таким образом, не сложно определить, что данная вычислительная машина может адресовать $2^m$ уникальных ячеек памяти.

В общем случае Кэш-память организована в виде **наборов** (`sets`).

Каждый из наборов содержит **линии кэша** (`cache lines`).

Пусть $E$ - количество линий кэша в наборе (`cache lines per set`). Тогда: 

- Если $E = 1$, то кэш является **прямо-отображаемым** (`direct-mapped cache`)
- Если $E>1$, то кэш называется **ассоциативным** (`set-associative cache`)
 


При этом уже **каждая линия кэша содержит блок данных**.

Каждый блок данных в линии кэша состоит из:
- $B = 2^b$ байт
- **бита достоверности** (`valid bit`), указывающего, содержит ли строка значащую информацию
- **разрядов тега** (`tag bits`) 