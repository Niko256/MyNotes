Придём к определению данного понятия исходя из проблемы: Представим веб-сервер, который должен обрабатывать тысячи и более клиентских подключений. Каждое из подключений представлено сокетом (файловым дескриптором). Соответственно, серверу необходимо иметь информацию, появились ли новые данные от клиента для чтения, а также, можно ли отправить данные клиенту, не заблокировавшись при этом.

Традиционный подход - использовать блокирующие системные вызовы (`read`, `write`). Но если сервер заблокируется на чтении от одного клиента, он не сможет обслуживать остальных. Использование отдельного потока на каждое соединение решает проблему, но становится ООчень неэффективным из-за больших накладных расходов (например на переключения контекстов потоков) при большом количестве соединений.

Таким образом, мы пришли к необходимости определить механизм, который бы позволял каждому потоку эффективно отслеживать состояние множества файловых дескрипторов, не блокируясь на каждом из них по отдельности. Такой метод называется **I/O Мультиплексирование** (`I/O Multiplexing`).


Важно упомянуть, что хоть этот механизм и решил эту проблему, но в `Linux` первое время он был реализован крайне неэффективным образом. Кратко упомянем старые подходы: `select` и `poll`:

1. **select**:
    - Работает с наборами файловых дескрипторов (`fd_set`)
        
    - Имел ограничение на максимальный номер дескриптора (`FD_SETSIZE`, обычно 1024), что делает его непригодным для высоконагруженных систем
        
    - При каждом вызове ядро должно линейно сканировать все дескрипторы в переданных наборах, чтобы проверить их состояние. Это $O(N)$, где $N$ — максимальный номер дескриптора, а не количество отслеживаемых.
        
    - После возврата из `select` пользовательский код должен снова линейно сканировать наборы, чтобы найти, какие именно дескрипторы стали готовы.
        
2. **poll**:
    - Улучшение над `select`. Снимает ограничение `FD_SETSIZE`.
        
    - Работает с массивом структур `pollfd`, каждая из которых содержит дескриптор и запрашиваемые события.
        
    - Ядро всё ещё должно линейно сканировать весь переданный массив дескрипторов при каждом вызове для проверки состояния. Это $O(M)$, где $M$ — количество отслеживаемых дескрипторов. Это лучше, чем `select`, но всё ещё не оптимально при тысячах соединений.

    - Пользовательский код после возврата также должен сканировать массив для поиска готовых дескрипторов.


Затем было введено более эффективное решение: семейство системных вызовов `epoll`.

## `epoll system calls`


`epoll` эффективно работает с тысячами дескрипторов, не требует линейного сканирования при каждом вызове, а также позволяет добавлять дескрипторы без полного перестроения набора. 

Данное семейство представлено в ядре `Linux` тремя системными вызовами: 
- `epoll_create1(flags)
- `epoll_ctl(epfd, op, fd, event)`
- `epoll_wait(epfd, events, maxevents, timeout)`

Разберём каждый из них по отдельности..

### `epoll_create1(flags)

Данный системный вызов создаёт экземпляр `epoll` в ядре и возвращает файловый дескриптор `epfd`, представляющий данный экземпляр. Этот дескриптор используется в оставшихся двух системных вызовах. 

Параметр `flags` определяет опции создания экземпляра `epoll`. Этот параметр может быть 0 (стандартное поведение) или `EPOLL_CLOEXEC` (рекомендуется), чтобы дескриптор `epoll` автоматически закрывался при выполнении `exec()` семейства вызовов.

``` c
int epoll_fd = epoll_create1(EPOLL_CLOEXEC);
if (epoll_fd == -1) {
    perror("epoll_create1");
    exit(EXIT_FAILURE);
}
```

### `epoll_ctl(epfd, op, fd, event)`

Данный системный вызов управляет мониторингом файловых дескрипторов.

``` c
int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event);
```

Параметры:

- `epfd`: дескриптор экземпляра `epoll`, полученный от `epoll_create1()`.
- `op`: операция (`EPOLL_CTL_ADD`, `EPOLL_CTL_MOD`, `EPOLL_CTL_DEL`)
	- `EPOLL_CTL_ADD`: Добавить дескриптор `fd` в список отслеживаемых
	- `EPOLL_CTL_MOD`: Изменить события, отслеживаемые для `fd`
	- `EPOLL_CTL_DEL`: Удалить дескриптор `fd` из списка.
- `fd`: дескриптор для мониторинга
	- Файловый дескриптор, который нужно добавить/изменить/удалить (например, сокет). **Важно:** Этот дескриптор должен поддерживать `epoll` (пайпы, сокеты, `eventfd`, `signalfd`, `timerfd` и т.д., но не обычные файлы на диске).
- `event`: указатель на структуру с настройками мониторинга


``` c
struct epoll_event {
    uint32_t events; // bit mask
    epoll_data_t data; 
};

typedef union epoll_data {
    void* ptr;
    int fd;
    uint32_t u32;
    uint64_t u64;
} epoll_data_t;
```

- `events`: Битовая маска интересующих событий:
    - `EPOLLIN`: Данные доступны для чтения
    - `EPOLLOUT`: Готовность к записи.
    - `EPOLLRDHUP`: закрытие соединения (для сокетов)
    - `EPOLLPRI`: Есть срочные данные для чтения.
    - `EPOLLERR`: Произошла ошибка на дескрипторе.
    - `EPOLLHUP`: Дескриптор "повешен" (`hang up`) (например, запись в закрытый пайп). epoll_wait всегда будет сообщать об этом событии, даже если оно не запрашивалось.

    - `EPOLLET`: Включить режим `Edge-Triggered (ET)`.

    - `EPOLLONESHOT`: После того как событие будет получено через `epoll_wait`, дескриптор автоматически отключается от `epoll` (как если бы вызвали `EPOLL_CTL_DEL`). Его нужно будет снова явно добавить (`EPOLL_CTL_MOD` или `EPOLL_CTL_ADD` после удаления), если нужно продолжать отслеживание. Это очень полезно в многопоточных обработчиках событий, чтобы избежать гонок, когда несколько потоков пытаются обработать одно и то же событие.

- `data`: Поле для хранения пользовательских данных, связанных с этим `fd`. Когда `epoll_wait` вернет событие для `fd`, он вернет и это поле `data`. Обычно сюда кладут указатель на структуру, представляющую соединение, или сам файловый дескриптор `fd`, чтобы быстро идентифицировать источник события.

``` c
+---------------------+
| events (EPOLLIN|ET) |
+---------------------+
| data.ptr            |
+---------------------+
                      |
                      v
                    +-----------------------+
                    | struct http_connection|
                    +-----------------------+
                    | fd = 42               |
                    | ip_addr = "192.168.1.1"|
                    | state = READING_HEADERS|
                    | buffer = {...}        |
                    | bytes_received = 0    |
                    +-----------------------+
```


### `epoll_wait(epfd, events, maxevents, timeout)`

Данный системный вызов ожидает наступления событий на дескрипторах, представленных в `epfd`.

``` c
int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout);
```

Параметры:
- `epfd`: Дескриптор экземпляра `epoll`
- `events`: Указатель на массив структур `struct epoll_event`, который будет заполнен ядром информацией о произошедших событиях
- `maxevents`: Размер массива `events` (т.е., максимальное количество событий, которое может быть возвращено за один вызов)
- `timeout`: Максимальное время ожидания в миллисекундах
    - -1: блокироваться бесконечно до появления события.
    - 0: не блокироваться, проверить наличие событий и немедленно вернуться
    - > 0: блокироваться не более указанного времени

`Return value`:
- > 0: Количество дескрипторов, готовых к `I/O` (и количество заполненных структур в массиве `events`)     
- 0: Таймаут истек, событий не произошло       
- -1: Произошла ошибка (проверяем `errno`). `EINTR` означает, что вызов был прерван сигналом, и его можно безопасно повторить

---
