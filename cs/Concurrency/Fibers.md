
## Motivation

В истории развития вычислительных систем мы постоянно сталкиваемся с фундаментальной проблемой: как эффективно утилизировать ресурс процессора, когда множество "задач" конкурируют за его внимание. Первоначальным решением были процессы - изолированные друг от друга сущности со своим собственным адресным пространством, управляемые планировщиком операционной системы. Однако создание процесса и переключение контекста между ними - это дорогостоящие операции, влекущие за собой значительные накладные расходы.

Эволюционным шагом стало появление [потоков](obsidian://open?vault=my_notes&file=cs%2FConcurrency%2FThreads) (`threads`). Потоки существуют в рамках одного процесса и разделяют его виртуальное адресное пространство. Это значительно удешевило  создание и переключение контекста, поскольку ядру операционной системы не требовалось переключать таблицы страниц виртуальной памяти. Модель, используемая потоками, называется **вытесняющей многозадачностью (`preemptive multitasking`)**. В этой модели планировщик в любой момент времени может прервать выполнение одного потока и передать управление другому, основываясь на приоритетах или системных событиях.

Эта модель прекрасно работает для `CPU-bound` задач и для обеспечения отзывчивости пользовательских интерфейсов. Однако она демонстрирует свои слабые стороны в сценариях с экстремально высоким уровнем конкуренции, особенно для задач, ограниченных "вводом-выводом" (`I/O-bound`). В качестве такой задачи достаточно представить себе веб-сервер, который должен одновременно обслуживать десятки тысяч или даже сотни тысяч соединений. Каждое соединение большую часть времени ничего не делает - оно ждёт данных из сети. В таком случае при создании отдельного потока для каждого соединения может привести к катастрофе, так как каждый поток требует выделение стека в ядре и в пользовательском пространстве. 100000 потоков потребуют гигабайты памяти только под стеки. Также, даже относительно лёгкое переключение контекста потока требует использование системного вызова для перехода в режим ядра и обратно. Это сотни, а то и тысячи тактов процессора. Когда переключений очень много, суммарные накладные расходы становятся доминирующим фактором, снижающим производительность системы.

Однако, для (`I/O-bound`) задач крайне эффективно использование альтернативной парадигмы планирования - **кооперативной многозадачности (`Cooperative multitasking`)**. Данная парадигма реализуется через ***файберы***.

## Definition

***Файбер (`fiber`)*** - это легковесный поток исполнения, жизненный цикл которого полностью управляется в пользовательском адресном пространстве, без прямого участия планировщика операционной системы.

В различных контекстах можно встретить эквивалентные или близкие по значению термины: `green threads`, `user-space threads`, `tasklets` или `microthreads`. Часто используется термин "корутина" (`coroutine`), однако обычно он подразумевает реализацию на уровне языка программирования, в то время как файбер чаще относится к системной концепции. Для наших целей мы будем считать эти термины взаимозаменяемыми.

Ключевое отличие файбера от классического потока кроется в модели планирования. Вместо вытесняющей многозадачности, файберы реализуют кооперативную. **Это означает, что файбер будет выполняться до тех пор, пока он добровольно не передаст управление планировщику файберов.** Передача управления осуществляется явным вызовом специальной функции, например, yield(). Таким образом, идея переключения контекста переносится из пространства ядра в пространство пользователя, а сами переключения становятся осознанной и явной частью вычислительного процесса.

## Internals

Прежде чем погружаться в детали реализации, необходимо провести фундаментальное различие между двумя моделями использования файберов.

- **Модель `N:1`** предполагает, что `N` файберов исполняются на одном-единственном потоке операционной системы. Весь асинхронный код выполняется последовательно на этом потоке, а файберы кооперативно делят его между собой. Эта модель лежит в основе `async/await` в `JavaScript` и `Python`, а также корутин в `Lua`. Ее главным преимуществом является отсутствие проблем с гонкой данных, так как истинный параллелизм отсутствует. Однако она не позволяет полноценно раскрыть мощь многоядерных процессоров.

- **Модель `M:N`**  - это более сложная и мощная концепция, где `M` файберов распределяются для исполнения по пулу из `N` потоков  (`M > N`). Именно эта модель представляет наибольший интерес для высокопроизводительных приложений, так как она сочетает масштабируемость файберов с истинным параллелизмом потоков. **Важно понимать: в модели `M:N` все классические проблемы многопоточности, такие как гонки данных, взаимоблокировки (`deadlocks`) и необходимость синхронизации, возвращаются**, поскольку несколько файберов могут исполняться действительно параллельно на разных ядрах процессора.


Далее мы будем рассматривать механизм работы файберов преимущественно в контексте более общей и сложной модели `M:N`.

- **Контекст исполнения** - это `snapshot` состояния процессора, необходимый для продолжения вычислений с прерванного места. Контекст обычно включает в себя:
	- `Instruction pointer (rip/eip)` - адрес следующей инструкции для выполнения.
	- `Stack pointer (rsp/esp)` - вершина стека файбера.
	- Значения регистров общего назначения (`rax, rbx, ...`) - значения операндов, используемых в текущих вычислениях

- `Stack` - у каждого файбера есть собственный, отдельный стек. Он используется для хранения локальных переменных, адресов возврата, точно также, как и у классического потока. Размер этого стека значительно меньше, чем у классического потока. Наличие собственного стека — это то, что определяет файберы как `stackful coroutines`. Это позволяет писать код в привычном процедурном стиле, с вызовами функций, локальными переменными и рекурсией, в отличие от `stackless coroutines`, где компилятор должен преобразовывать код, накладывая ограничения на точки приостановки выполнения.

- Планировщик (`sheduler`) - это компонент, ответственный за управление файберами. В его ответственность входит создание и уничтожение файберов, хранение очереди готовых к исполнению файберов, сохранение контекста при вызове `yield`, восстановление контекста и передача управление следующему файберу из очереди. (+ В модели `M:N`, распределение файберов по рабочим потокам).

### Context switch

В отличие от потоков ОС, где переключение контекста — прерогатива ядра, файберы реализуют этот механизм в пространстве пользователя. Это достигается за счет прямого манипулирования регистрами процессора с помощью коротких ассемблерных вставок.

**Следует избегать системных примитивов для работы с контекстом**, таких как `ucontext` в `POSIX` или `CreateFiber` в `Windows`. Они либо устарели, либо несут избыточные накладные расходы, либо накладывают ограничения (например, не позволяют использовать собственный аллокатор для стеков).

Эффективная реализация сводится к двум  инструкциям, инкапсулирующим ассемблерные вставки, специфичным для конкретной архитектуры и `ABI`:

- `get_context(context*)`: Сохраняет значения критически важных регистров и `rip` в переданную структуру `context`

- `set_context(context*)`: Восстанавливает значения регистров из структуры `context` и выполняет нелокальный переход, фактически загружая в `rip` сохранённый адрес.

Комбинируя их, можно реализовать `swap_context(old_ctx*, new_ctx*)` — функцию, которая сохраняет текущий контекст в `old_ctx` и немедленно восстанавливает новый из `new_ctx`. Это сердце файбера. 

---
## Nested induced Deadlocks

Может возникнуть вопрос: чем модель `M:N` файберов отличается от классического пула потоков (`thread pool`), исполняющего задачи (`tasks`)? Различие фундаментально проявляется в проблеме, которую можно назвать **вложенно-индуцированной взаимоблокировкой**.

Представим загрузку игрового уровня: `LoadLevel` порождает задачи для загрузки моделей `LoadModel`, которые в свою очередь, порождают задачи `LoadMesh` и `LoadMaterial`, и так далее... Если на каждом уровне вложенности родительская задача будет ждать завершения дочерних, очень быстро все `N` потоков пула окажутся заблокированными в ожидании, в то время как порождённые ими задачи не смогут начать выполняться, так как свободных потоков в пуле не осталось. Это является наглядным представлением взаимоблокировки (`deadlock`).

Файберы красиво решают эту проблему. Когда файбер вызывает ожидающую функцию, она на самом деле не блокирует родительский для файбера поток, а вместо этого уступает управление (`yields`). Планировщик переводит текущий файбер в состояние ожидания и немедленно запускает на освободившемся потоке одну из дочерних задач. Таким образом, родительский поток всегда останется загруженным полезной работой.

---

На первый взгляд, модель кооперативной многозадачности выглядит безупречно, но у неё есть фундаментальная уязвимость. Что произойдёт, если один из файберов выполнит классический блокирующий системный вызов, например `read()` на сетевом сокете, в котором пока нет данных? В этот момент управление переходит к ядру операционной системы. Ядро, обнаружив, что операция не может быть выполнена немедленно, переводит весь родительский для файберов поток в состояние ожидания. Вместе с ним блокируется работа всех файберов, которые исполнялись в этом потоке. Вся элегантная система кооперативной многозадачности коллапсирует и производительность падает до нуля.

Избежать данную проблему возможно, если всегда следовать универсальному правилу работы с файберами. Оно гласит, что ***правильная реализация системы на файберах никогда не использует блокирующие системные вызовы напрямую.***


Как было сказано, модель файберов рушится, если один из них выполняет **блокирующий** системный вызов. Он замораживает весь родительский поток выполнения. 

Решение этой проблемы заключается в полной и безаговорочной замене всех блокирующих операций их асинхронными аналогами, построенными вокруг архитектурного паттерна `Reactor`. Вопреки распостранённому упрощению, роль реактора, как правило, не выделяется в отдельный специализированный поток. Вместо этого его функциональность интегрируется в основной рабочий цикл каждого потока пула, который исполняет файберы. Для пользователя это будет выглядеть как простой вызов `socket.read()`, который не блокирует систему. Внутри вызова же разворачивается сложная, но строгая упорядоченная последовательность действий.

В момент, когда `fiber` инициирует операцию ввода-вывода через предоставляемую библиотекой функцию-обёртку, первым делом совершается оптимистическая попытка выполнения в неблокирующем режиме. Если ресурс уже доступен в буфере ядра, он немедленно считывается, и функция возвращает результат, минуя все дальнейшие сложности. Если же данные отсутствуют, то вступает в работу основной механизм. Функция-обёртка регистрирует файловый дескриптор сокета через неблокирующее семейство системных вызовов (`epoll/kqueue/IOCP`), связывая его с контекстом текущего файбера. Эта связка - залог того, что система будет знать, кого именно поднимать в будущем. Сразу после успешной регистрации файбер добровольно уступает управление, вызывая `yeild()`, и переводится планировщиком файбера в состояние ожидания, не блокируя при этом родительский поток.

В этот момент поток пула продолжает свою работу: он исполняет другие готовые файберы, а в перерывах кратковременно опрашивает системный монитор событий вызовом `epoll_wait()` (или его аналогом в зависимости от системы). Этот вызов мгновенно возвращает список дескрипторов, на которых произошли события. Обрабатывая этот список, планировщик файберов использует сохранённую ранее связку, чтобы определить, какой файбер ожидал каждого конкретного события, и перемещает его из очереди ожидания обратно в очередь готовых к исполнению.

При следующей итерации планировщик файберов в конечном итоге выберет поднятый файбер и восстановит его контекст. Исполнение возобновится ровно с того места, где оно было приостановлено, - внутри функции-обёртки. Теперь она может повторить неблокирующий системный вызов, который на этот раз гарантированно завершится успехом. Для вызывающего кода вся эта сложная последовательность вызовов выглядит как единый, но не блокирующий систему вызов функции, что позволяет сохранить простоту синхронной модели программирования при сохранении эффективности асинхронности внутри.


---

## LINKS:

1. `boost/fiber`:
	- [class](https://www.boost.org/doc/libs/develop/libs/context/doc/html/context/ff.html)
	- [`context switching`](https://www.boost.org/doc/libs/develop/libs/context/doc/html/context/ff.html)
2. [`fibers without scheduler`](https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0876r0.pdf)
3. [`overview`](https://graphitemaster.github.io/fibers/)
