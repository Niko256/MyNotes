# The Memory Hierarchy and Basic Concepts of Caching

***Кэш (cache)*** - это высокоскоростная память небольшого объёма, используемая для временного хранения данных или инструкций, к которым процессор обращается наиболее часто. Основным его преимуществом является снижение среднего времени доступа к данным.

В архитектуре `x86-64` кэш обычно организован в виде иерархии уровней (`L1, L2, L3`), где каждый из уровней имеет разную скорость и объём.

***Кэширование*** - это механизм управления кэшем, включающий поиск данных в кэше, их загрузку в кэш при промахе (`cache miss`) и вытеснение данных из кэша в соответствии с выбранной стратегией.


Как было указано ранее, кэш состоит из нескольких уровней. Каждый уровень кэша оптимизирован для баланса между скоростью доступа, объёмом и энергопотреблением.

Каждый из уровней представляет из себя набор транзисторов, организованных в триггеры (`flip-flops`), которые хранят биты данных.

Для начала рассмотрим общую идею кэширования в иерархии памяти.

![The memory hierarchy|500px](https://i.imgur.com/rI77oDl.png)


Иерархия памяти состоит из нескольких уровней, где каждый уровень (например, уровень `k` и уровень `k+1`) имеет свои характеристики по объему, скорости доступа и стоимости.

Память на каждом уровне иерархии разделена на **блоки** — непрерывные фрагменты данных. Блоки могут быть фиксированного или переменного размера.

Кэш на уровне `k` содержит копии подмножества блоков из уровня `k+1`. Например:

![levels](https://i.imgur.com/YzV3QhK.jpeg)


Это означает, что кэш хранит только часть данных из более медленной памяти, чтобы ускорить доступ к ним.


Данные передаются между уровнями `k` и `k+1` блоками фиксированного размера.

Устройства, находящиеся ниже в иерархии, имеют большее время доступа. Чтобы компенсировать это, используются блоки большего размера. Передача больших блоков данных позволяет "амортизировать" (распределить) длительное время доступа, так как за один запрос передается больше данных.

---


---
# General organization of cache

Иерархии памяти первых компьютерных систем состояли всего из трёх уровней: регистров процессора, основной памяти `DRAM` и дисковых устройств.

Однако из-за увеличивающейся разницы в быстродействии между регистрами процессора и основной `DRAM` памятью проектировщики были вынуждены добавить `SRAM (Static Random Accessed Memory)` - кэш `L1`. Он расположен между блоком регистров и основной `DRAM` памятью и его время доступа сопоставимо со временем доступа к регистрам.

![|550px](https://i.imgur.com/4AOvyUj.png)

С увеличением разницы в быстродействии между процессорами и основной `DRAM` памятью проектировщики компьютерных систем были вынуждены вводить дополнительные уровни кешей. 

Это позволило еще больше сократить время ожидания процессора и повысить общую производительность систем. Таким образом были добавлены кэши `L2` и `L3`.

Общие принципы остались неизменны, за исключением того, что уровни `L2` и `L3` также встроились в иерархию памяти и упорядочены по времени доступа и объёму с каждым уровнем.

Далее мы рассмотрим общую структуру и внутреннее устройство почти любого кэша в современной вычислительной машине.

---

## Internal Cache Organization and N-way Set Associativity

Концептуально, кэш каждого уровня можно рассматривать как специализированную хеш-таблицу, где в роли ключей выступают физические адреса ячеек памяти в оперативной памяти, а в роли значений - кэш-линии, содержащие копии данных по этим адресам.

Физический адрес, поступающий в кэш, делится на три логических поля: **тег (tag)**, **индекс (index)** и **смещение (offset)**. Поле индекса используется для выбора конкретной группы ячеек в кэш-памяти, называемой **сетом (set)**. Каждый сет состоит из одной или нескольких **кэш-линий (cache lines)**, также называемых блоками. 

Кэш-линия — это минимальная единица данных, которыми оперирует кэш : её размер обычно составляет 64 байта в современных системах. 

*Поле смещения определяет конкретный байт внутри кэш-линии.*

Тег - это старшая часть адреса, которая хранится рядом с данными в кэш-линии и служит для идентификации того, какой именно блок из оперативной памяти содержится в данной линии. При выполнении запроса на чтение или запись аппаратура кэша использует индекс для выбора сета, а затем параллельно сравнивает тэг запрашиваемого адреса с тегами всех линий в выбранном сете.

Если тег совпадает и линия помечена как действительная (`valid`), происходит попадание в кэш.

Помимо данных и тега, каждая кэш-линия хранит служебные биты состояния. Наиболее критичным является бит валидности (`valid bit`), который указывает, содержит ли данная линия актуальные данные. Линия с сброшенным битом валидности считается пустой и не учавствует в проверке на попадание. В кэшах, обеспечивающих когерентность в многоядерных системах, также используются биты модификации (`dirty bit`), отмечающие была ли линия перезаписана относительно своей копии в оперативной памяти, а также биты состояния протокола когерентности. Эти биты определяют, необходимо ли записывать вытесняемую линию обратно в память и как согласовывать её состояние с другими кэшами на других ядрах.

---

Способ отображения блоков оперативной памяти на кэш-линии определяется **ассоциативностью кэша**. Ассоциативность является компромиссом между простотой реализации, скоростью доступа и частотой конфликтных промахов.

N-ассоциативный кэш (`N-way set-associative cache`) - это наиболее распостранённая на практике архитектура, являющаяся комбинацией полного ассоциативного и прямого отображения кэшей.

![](https://i.imgur.com/BNjhL5L.png)
В N-ассоциативном кэше всё кэш-хранилище разбито на некоторое количество сетов. Каждый сет содержит ровно `N` кэш-линий, где `N` - это степень ассоциативности. Блок из байт из оперативной памяти может быть размещён в любой из этих `N` линий одного конкретного сета. Сет для данного блока однозначно определяется полем индекса в его физическом адресе. Таким образом, механизм работы такого кэша можно представить как массив сетов, где каждый сет является небольшой полностью ассоциативной памятью на `N` записей.

Когда процессор делает обращение к ячейке с физическим адресом, аппаратура кэша извлекает из адреса поле индекса и выбирает соответствующий сет. Затем она параллельно сравнивает тег данного адреса с тегами всех `N` линий в этом сете. Это сравнение требует `N` компараторов. То так как сет зачастую относительно малого размера (обычно `N` = 2) => данный поиск вполне эффективен, несмотря на то, что он линейный. Если тег совпадает с одним из тегов в сете и бит валидности установлен, то происходит попадание в кэш (`cache hit`), и блок байт читается из соответствующей линии (`set -> line + offset = sought bytes`).
Если совпадение не найдено, то констатируется промах в кэш (`cache miss`), и блок байт подкачивается из более низкого уровня иерархии памяти.

![|350](https://i.imgur.com/C4mCc6a.png)


При промахе и необходимости разместить новый блок в уже заполненном сете (все `N` линий заняты) кэш использует механизм стратегии замены. Для N-ассоциативных кэшей типичными стратегиями являются `LRU` и `Round-Robin`. Выбранная стратегия определяет, какая именно линия в сете будет выбрана в качестве жертвы для вытеснения.

---

### Critical concepts

Принцип локальности является главным обоснованием самой идеи кэширования и объясняет его эффективность. Он делится на 2 основных типа локальности.

1. **Пространственная локальность** предполагает, что если процессор обращается к некоторой ячейке памяти, то с высокой вероятностью в ближайшем будущем он обратится к соседним ячейкам. Это и обосновывает использование кэш-линий как минимальных единиц хранения данных, ведь при промахе в кэш загружается не один байт, а весь блок, образующий линию и охватывающий область вокруг запрошенного адреса.
	
2. **Временная локальность** предполагает, что к данным, к которым только что было обращение, с высокой вероятностью снова обратятся в ближайшем будущем. Это обосновывает саму идею хранения недавно использованных данных в быстрой памяти близко к процессору. 


И оптимизация кода часто сводится к увеличению степени локальности обращений к памяти, что и приводит к росту числа попаданий в кэш.

---

## [Cache coherency](https://github.com/Niko256/MyNotes/blob/main/Concurrency/Atomic%20operations.md#cache-coherency)
